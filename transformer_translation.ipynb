{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8149573,"sourceType":"datasetVersion","datasetId":4819712},{"sourceId":8343872,"sourceType":"datasetVersion","datasetId":4956174},{"sourceId":8350042,"sourceType":"datasetVersion","datasetId":4960934},{"sourceId":8353406,"sourceType":"datasetVersion","datasetId":4963298}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('/kaggle/input/eng-hing/train.txt', names=['en', 'hing'], usecols=['en', 'hing'], sep='\\t')\ndf = df.sample(frac=1, random_state=42)\ndf = df.reset_index(drop=True)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-08T11:22:08.978337Z","iopub.execute_input":"2024-05-08T11:22:08.979226Z","iopub.status.idle":"2024-05-08T11:22:11.191894Z","shell.execute_reply.started":"2024-05-08T11:22:08.979192Z","shell.execute_reply":"2024-05-08T11:22:11.191027Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:22:11.193591Z","iopub.execute_input":"2024-05-08T11:22:11.193899Z","iopub.status.idle":"2024-05-08T11:22:11.213932Z","shell.execute_reply.started":"2024-05-08T11:22:11.193860Z","shell.execute_reply":"2024-05-08T11:22:11.213007Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                                       en  \\\n0                           How to play with other people   \n1                           One Hundred Years of Solitude   \n2         Take this route with the help of a local person   \n3                        for the People of the Right Hand   \n4          And those who are fearful of their Lord s doom   \n...                                                   ...   \n248324  to lasting friendship between India and Mozamb...   \n248325        Google Drive cannot be reached at this time   \n248326                     Here this is my new sweetheart   \n248327  Let them remember that nature is the finest ph...   \n248328  And so these findings I think are really very ...   \n\n                                                     hing  \n0                          other people के साथ कैसे खेलें  \n1                                    Solitude के सौ Years  \n2       किसी स्थानीय व्यक्ति की help से इसी route को प...  \n3       दाहिने हाथ में नामए आमाल लेने People के वास्ते है  \n4              और जो लोग अपने Lord के doom से fearful हैं  \n...                                                   ...  \n248324  India और मोजाम्बिक के बीच स्थायी मैत्री की काम...  \n248325        इस time Google Drive तक नहीं पहुंचा जा सकता  \n248326                     यहाँ यह मेरी new sweetheart है  \n248327  उन्हें यह याद रखना चाहिये कि finest physician ...  \n248328  और इसलिए मैं सोचता हूँ की यह findings परिणाम ब...  \n\n[248329 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en</th>\n      <th>hing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>How to play with other people</td>\n      <td>other people के साथ कैसे खेलें</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>One Hundred Years of Solitude</td>\n      <td>Solitude के सौ Years</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Take this route with the help of a local person</td>\n      <td>किसी स्थानीय व्यक्ति की help से इसी route को प...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>for the People of the Right Hand</td>\n      <td>दाहिने हाथ में नामए आमाल लेने People के वास्ते है</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>And those who are fearful of their Lord s doom</td>\n      <td>और जो लोग अपने Lord के doom से fearful हैं</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>248324</th>\n      <td>to lasting friendship between India and Mozamb...</td>\n      <td>India और मोजाम्बिक के बीच स्थायी मैत्री की काम...</td>\n    </tr>\n    <tr>\n      <th>248325</th>\n      <td>Google Drive cannot be reached at this time</td>\n      <td>इस time Google Drive तक नहीं पहुंचा जा सकता</td>\n    </tr>\n    <tr>\n      <th>248326</th>\n      <td>Here this is my new sweetheart</td>\n      <td>यहाँ यह मेरी new sweetheart है</td>\n    </tr>\n    <tr>\n      <th>248327</th>\n      <td>Let them remember that nature is the finest ph...</td>\n      <td>उन्हें यह याद रखना चाहिये कि finest physician ...</td>\n    </tr>\n    <tr>\n      <th>248328</th>\n      <td>And so these findings I think are really very ...</td>\n      <td>और इसलिए मैं सोचता हूँ की यह findings परिणाम ब...</td>\n    </tr>\n  </tbody>\n</table>\n<p>248329 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nimport re\nfrom unicodedata import normalize\n\n\ndef clean_text(text, language='en'):\n    if isinstance(text, float) and np.isnan(text):  # Check if text is NaN\n        return ''  # Return empty string for NaN values\n    text = normalize('NFD', text)\n    if language == 'en':\n        text = re.sub('[^A-Za-z .\\']+', '', text)\n    elif language == 'hing': \n        text = re.sub('[^\\u0900-\\u097F A-Za-z .\\']+', '', text)\n    return text\n\ndef clean_and_prepare_text(text, language='hing'):\n    text = '[start] ' + clean_text(text, language=language) + ' [end]'\n    return text\n\n# Apply it to your dataframe like this:\ndf['en'] = df['en'].apply(lambda row: clean_text(row, language='en'))\ndf['hing'] = df['hing'].apply(lambda row: clean_and_prepare_text(row, language='hing'))\ndf\n","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:22:11.215408Z","iopub.execute_input":"2024-05-08T11:22:11.215820Z","iopub.status.idle":"2024-05-08T11:22:13.397340Z","shell.execute_reply.started":"2024-05-08T11:22:11.215788Z","shell.execute_reply":"2024-05-08T11:22:13.396260Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                       en  \\\n0                           How to play with other people   \n1                           One Hundred Years of Solitude   \n2         Take this route with the help of a local person   \n3                        for the People of the Right Hand   \n4          And those who are fearful of their Lord s doom   \n...                                                   ...   \n248324  to lasting friendship between India and Mozamb...   \n248325        Google Drive cannot be reached at this time   \n248326                     Here this is my new sweetheart   \n248327  Let them remember that nature is the finest ph...   \n248328  And so these findings I think are really very ...   \n\n                                                     hing  \n0            [start] other people के साथ कैसे खेलें [end]  \n1                      [start] Solitude के सौ Years [end]  \n2       [start] किसी स्थानीय व्यक्ति की help से इसी ro...  \n3       [start] दाहिने हाथ में नामए आमाल लेने People क...  \n4       [start] और जो लोग अपने Lord के doom से fearful...  \n...                                                   ...  \n248324  [start] India और मोजाम्बिक के बीच स्थायी मैत्र...  \n248325  [start] इस time Google Drive तक नहीं पहुंचा जा...  \n248326       [start] यहाँ यह मेरी new sweetheart है [end]  \n248327  [start] उन्हें यह याद रखना चाहिये कि finest ph...  \n248328  [start] और इसलिए मैं सोचता हूँ की यह findings ...  \n\n[248329 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en</th>\n      <th>hing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>How to play with other people</td>\n      <td>[start] other people के साथ कैसे खेलें [end]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>One Hundred Years of Solitude</td>\n      <td>[start] Solitude के सौ Years [end]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Take this route with the help of a local person</td>\n      <td>[start] किसी स्थानीय व्यक्ति की help से इसी ro...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>for the People of the Right Hand</td>\n      <td>[start] दाहिने हाथ में नामए आमाल लेने People क...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>And those who are fearful of their Lord s doom</td>\n      <td>[start] और जो लोग अपने Lord के doom से fearful...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>248324</th>\n      <td>to lasting friendship between India and Mozamb...</td>\n      <td>[start] India और मोजाम्बिक के बीच स्थायी मैत्र...</td>\n    </tr>\n    <tr>\n      <th>248325</th>\n      <td>Google Drive cannot be reached at this time</td>\n      <td>[start] इस time Google Drive तक नहीं पहुंचा जा...</td>\n    </tr>\n    <tr>\n      <th>248326</th>\n      <td>Here this is my new sweetheart</td>\n      <td>[start] यहाँ यह मेरी new sweetheart है [end]</td>\n    </tr>\n    <tr>\n      <th>248327</th>\n      <td>Let them remember that nature is the finest ph...</td>\n      <td>[start] उन्हें यह याद रखना चाहिये कि finest ph...</td>\n    </tr>\n    <tr>\n      <th>248328</th>\n      <td>And so these findings I think are really very ...</td>\n      <td>[start] और इसलिए मैं सोचता हूँ की यह findings ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>248329 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"en = df['en']\nhing = df['hing']\n\nen_max_len = max(len(line.split()) for line in en)\nhing_max_len = max(len(line.split()) for line in hing)\nsequence_len = max(en_max_len, hing_max_len)\n\n\n# eng = [line for line in en if len(line.split())>10]\n# print(f'Max phrase length (English): {en_max_len}')\n# print(f'Max phrase length (Hinglish): {hing_max_len}')\n# print(f'Sequence length: {sequence_len}')","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:22:13.399521Z","iopub.execute_input":"2024-05-08T11:22:13.399831Z","iopub.status.idle":"2024-05-08T11:22:13.873588Z","shell.execute_reply.started":"2024-05-08T11:22:13.399805Z","shell.execute_reply":"2024-05-08T11:22:13.872568Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nen_tokenizer = Tokenizer()\nen_tokenizer.fit_on_texts(en)\nen_sequences = en_tokenizer.texts_to_sequences(en)\nen_x = pad_sequences(en_sequences, maxlen=sequence_len, padding='post')\n\nhing_tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@\\\\^_`{|}~\\t\\n')\nhing_tokenizer.fit_on_texts(hing)\nhing_sequences = hing_tokenizer.texts_to_sequences(hing)\nhing_y = pad_sequences(hing_sequences, maxlen=sequence_len + 1, padding='post')","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:22:13.874981Z","iopub.execute_input":"2024-05-08T11:22:13.875312Z","iopub.status.idle":"2024-05-08T11:22:46.963295Z","shell.execute_reply.started":"2024-05-08T11:22:13.875286Z","shell.execute_reply":"2024-05-08T11:22:46.962450Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-05-08 11:22:15.618534: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-08 11:22:15.618656: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-08 11:22:15.754143: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"en_vocab_size = len(en_tokenizer.word_index) + 1\nhing_vocab_size = len(hing_tokenizer.word_index) + 1\n\nprint(f'Vocabulary size (English): {en_vocab_size}')\nprint(f'Vocabulary size (Hinglish): {hing_vocab_size}')","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:22:46.964493Z","iopub.execute_input":"2024-05-08T11:22:46.965072Z","iopub.status.idle":"2024-05-08T11:22:46.970660Z","shell.execute_reply.started":"2024-05-08T11:22:46.965025Z","shell.execute_reply":"2024-05-08T11:22:46.969694Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Vocabulary size (English): 63518\nVocabulary size (Hinglish): 101275\n","output_type":"stream"}]},{"cell_type":"code","source":"hing_y[:,:-1]","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-05-08T11:22:46.972018Z","iopub.execute_input":"2024-05-08T11:22:46.972354Z","iopub.status.idle":"2024-05-08T11:22:46.989427Z","shell.execute_reply.started":"2024-05-08T11:22:46.972325Z","shell.execute_reply":"2024-05-08T11:22:46.988366Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"array([[    1,   105,    89, ...,     0,     0,     0],\n       [    1, 15225,     5, ...,     0,     0,     0],\n       [    1,    38,  2384, ...,     0,     0,     0],\n       ...,\n       [    1,   123,    18, ...,     0,     0,     0],\n       [    1,   109,    18, ...,     0,     0,     0],\n       [    1,     8,   277, ...,     0,     0,     0]], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"inputs = { 'encoder_input': en_x, 'decoder_input': hing_y[:, :-1] }\noutputs = hing_y[:, 1:]","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:22:46.990712Z","iopub.execute_input":"2024-05-08T11:22:46.991048Z","iopub.status.idle":"2024-05-08T11:22:46.997773Z","shell.execute_reply.started":"2024-05-08T11:22:46.991014Z","shell.execute_reply":"2024-05-08T11:22:46.996809Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Input, Dense, Dropout\nfrom keras_nlp.layers import TokenAndPositionEmbedding, TransformerEncoder\nfrom keras_nlp.layers import TransformerDecoder\n\nnp.random.seed(42)\ntf.random.set_seed(42)\n\nnum_heads = 8\nembed_dim = 256\n\nencoder_input = Input(shape=(None,), dtype='int64', name='encoder_input')\nx = TokenAndPositionEmbedding(en_vocab_size, sequence_len, embed_dim)(encoder_input)\nencoder_output = TransformerEncoder(embed_dim, num_heads)(x)\nencoded_seq_input = Input(shape=(None, embed_dim))\n\ndecoder_input = Input(shape=(None,), dtype='int64', name='decoder_input')\nx = TokenAndPositionEmbedding(hing_vocab_size, sequence_len, embed_dim, mask_zero=True)(decoder_input)\nx = TransformerDecoder(embed_dim, num_heads)(x, encoded_seq_input)\nx = Dropout(0.4)(x)\n\ndecoder_output = Dense(hing_vocab_size, activation='softmax')(x)\ndecoder = Model([decoder_input, encoded_seq_input], decoder_output)\ndecoder_output = decoder([decoder_input, encoder_output])\n\nmodel = Model([encoder_input, decoder_input], decoder_output)\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.summary(line_length=120)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:22:46.998963Z","iopub.execute_input":"2024-05-08T11:22:46.999378Z","iopub.status.idle":"2024-05-08T11:22:49.741212Z","shell.execute_reply.started":"2024-05-08T11:22:46.999315Z","shell.execute_reply":"2024-05-08T11:22:49.740199Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n│ encoder_input (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                 │                 \u001b[38;5;34m0\u001b[0m │ -                         \n├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n│ token_and_position_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m16,289,792\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n│ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)       │                              │                   │                           \n├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n│ decoder_input (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                 │                 \u001b[38;5;34m0\u001b[0m │ -                         \n├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n│ transformer_encoder               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │           \u001b[38;5;34m395,776\u001b[0m │ token_and_position_embeddi\n│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)              │                              │                   │                           \n├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n│ functional_1 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101275\u001b[0m)         │        \u001b[38;5;34m52,642,715\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n│                                   │                              │                   │ transformer_encoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape                 </span>┃<span style=\"font-weight: bold\">           Param # </span>┃<span style=\"font-weight: bold\"> Connected to              </span>\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n│ encoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n│ token_and_position_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,289,792</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)       │                              │                   │                           \n├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n│ decoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n│ transformer_encoder               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">395,776</span> │ token_and_position_embeddi\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)              │                              │                   │                           \n├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n│ functional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101275</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">52,642,715</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n│                                   │                              │                   │ transformer_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m69,328,283\u001b[0m (264.47 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,328,283</span> (264.47 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m69,328,283\u001b[0m (264.47 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,328,283</span> (264.47 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\n\n\ncallback = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\nhist = model.fit(inputs, outputs, epochs=50, validation_split=0.2, callbacks=[callback])","metadata":{"execution":{"iopub.status.busy":"2024-05-08T11:22:49.744529Z","iopub.execute_input":"2024-05-08T11:22:49.744831Z","iopub.status.idle":"2024-05-08T14:23:28.077496Z","shell.execute_reply.started":"2024-05-08T11:22:49.744808Z","shell.execute_reply":"2024-05-08T14:23:28.075292Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'position_embedding' (of type PositionEmbedding) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m   1/6209\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30:04:56\u001b[0m 17s/step - accuracy: 5.4825e-04 - loss: 11.5222","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1715167387.403329      81 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1715167387.433179      81 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.0273 - loss: 5.9769","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1715168210.529096      83 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1715168212.397020      83 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m918s\u001b[0m 145ms/step - accuracy: 0.0272 - loss: 5.9768 - val_accuracy: 0.0280 - val_loss: 5.1709\nEpoch 2/50\n\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m890s\u001b[0m 143ms/step - accuracy: 0.0293 - loss: 4.9860 - val_accuracy: 0.0313 - val_loss: 4.8307\nEpoch 3/50\n\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m891s\u001b[0m 144ms/step - accuracy: 0.0411 - loss: 4.4429 - val_accuracy: 0.0446 - val_loss: 4.6143\nEpoch 4/50\n\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m889s\u001b[0m 143ms/step - accuracy: 0.0558 - loss: 3.9520 - val_accuracy: 0.0360 - val_loss: 4.4895\nEpoch 5/50\n\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m887s\u001b[0m 143ms/step - accuracy: 0.0517 - loss: 3.5163 - val_accuracy: 0.0377 - val_loss: 4.3568\nEpoch 6/50\n\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m891s\u001b[0m 143ms/step - accuracy: 0.0717 - loss: 3.1540 - val_accuracy: 0.0523 - val_loss: 4.2974\nEpoch 7/50\n\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m894s\u001b[0m 144ms/step - accuracy: 0.0631 - loss: 2.8613 - val_accuracy: 0.0492 - val_loss: 4.2782\nEpoch 8/50\n\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m923s\u001b[0m 144ms/step - accuracy: 0.0763 - loss: 2.6259 - val_accuracy: 0.0619 - val_loss: 4.2821\nEpoch 9/50\n\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m893s\u001b[0m 144ms/step - accuracy: 0.0815 - loss: 2.4298 - val_accuracy: 0.0981 - val_loss: 4.2539\nEpoch 10/50\n\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m891s\u001b[0m 144ms/step - accuracy: 0.0944 - loss: 2.2637 - val_accuracy: 0.2678 - val_loss: 4.2884\nEpoch 11/50\n\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m890s\u001b[0m 143ms/step - accuracy: 0.1614 - loss: 2.1199 - val_accuracy: 0.2062 - val_loss: 4.3370\nEpoch 12/50\n\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m894s\u001b[0m 144ms/step - accuracy: 0.2549 - loss: 1.9976 - val_accuracy: 0.1168 - val_loss: 4.3545\nEpoch 13/50\n\u001b[1m 655/6209\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:14\u001b[0m 132ms/step - accuracy: 0.1373 - loss: 1.9252","output_type":"stream"},{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow.keras.backend as K\nfrom tensorflow.keras.models import save_model\n\n# Clear the Keras session and reset the graph\nK.clear_session()\n\n# Save the model\nsave_model(model, '/kaggle/working/model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef translate_text(text, model, en_tokenizer, fr_tokenizer, fr_index_lookup, sequence_len):\n    input_sequence = en_tokenizer.texts_to_sequences([text])\n    padded_input_sequence = pad_sequences(input_sequence, maxlen=sequence_len, padding='post')\n    decoded_text = '[start]'\n\n    for i in range(sequence_len):\n        target_sequence = fr_tokenizer.texts_to_sequences([decoded_text])\n        padded_target_sequence = pad_sequences(target_sequence, maxlen=sequence_len, padding='post')[:, :-1]\n        \n        prediction = model([padded_input_sequence, padded_target_sequence])\n\n        idx = np.argmax(prediction[0, i, :]) - 1\n        token = fr_index_lookup[idx]\n        decoded_text += ' ' + token\n\n        if token == '[end]':\n            break\n    \n    return decoded_text[8:-6] # Remove [start] and [end] tokens\n\n# fr_vocab = fr_tokenizer.word_index\n# fr_index_lookup = dict(zip(range(len(fr_vocab)), fr_vocab))\n# texts = en[40000:40010].values\n\n# for text in texts:\n#     translated = translate_text(text, model, en_tokenizer, fr_tokenizer, fr_index_lookup, sequence_len)\n#     print(f'{text} => {translated}')\n\nhing_vocab = hing_tokenizer.word_index\nhing_index_lookup = dict(zip(range(len(hing_vocab)), hing_vocab))\n\ndf_test = pd.read_csv('/kaggle/input/eng-hing/test.txt', names=['en', 'hing'], usecols=['en', 'hing'], sep='\\t')\ndf_test['en'] = df_test['en'].apply(lambda row: clean_text(row, language='en'))\ndf_test['hing'] = df_test['hing'].apply(lambda row: clean_and_prepare_text(row, language='hing'))\nen_test = df_test['en']\nhing_test = df_test['hing']\n\n\ntexts = en_test[:].values\ntranslated = []\n\nfor text in tqdm(texts):\n    translated.append(translate_text(text, model, en_tokenizer, hing_tokenizer, hing_index_lookup, sequence_len))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T15:03:10.452808Z","iopub.execute_input":"2024-05-08T15:03:10.453258Z","iopub.status.idle":"2024-05-08T15:09:35.110958Z","shell.execute_reply.started":"2024-05-08T15:03:10.453227Z","shell.execute_reply":"2024-05-08T15:09:35.109628Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"  0%|          | 0/2000 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'position_embedding' (of type PositionEmbedding) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n 40%|███▉      | 799/2000 [06:24<09:37,  2.08it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","Cell \u001b[0;32mIn[23], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m translated \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m tqdm(texts):\n\u001b[0;32m---> 45\u001b[0m     translated\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtranslate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43men_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhing_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhing_index_lookup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_len\u001b[49m\u001b[43m)\u001b[49m)\n","Cell \u001b[0;32mIn[23], line 14\u001b[0m, in \u001b[0;36mtranslate_text\u001b[0;34m(text, model, en_tokenizer, fr_tokenizer, fr_index_lookup, sequence_len)\u001b[0m\n\u001b[1;32m     10\u001b[0m padded_target_sequence \u001b[38;5;241m=\u001b[39m pad_sequences(target_sequence, maxlen\u001b[38;5;241m=\u001b[39msequence_len, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m)[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     12\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model([padded_input_sequence, padded_target_sequence])\n\u001b[0;32m---> 14\u001b[0m idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[43mprediction\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     15\u001b[0m token \u001b[38;5;241m=\u001b[39m fr_index_lookup[idx]\n\u001b[1;32m     16\u001b[0m decoded_text \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m token\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5882\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:GPU:0}} slice index 113 of dimension 1 out of bounds. [Op:StridedSlice] name: strided_slice/"],"ename":"InvalidArgumentError","evalue":"{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:GPU:0}} slice index 113 of dimension 1 out of bounds. [Op:StridedSlice] name: strided_slice/","output_type":"error"}]},{"cell_type":"code","source":"# translate_text('Hi world how are you?', model, en_tokenizer, fr_tokenizer, fr_index_lookup, sequence_len)\n\n# # Translating \"you are good\"\n# translated_text = translate_text_pytorch('you are good', model, en_tokenizer, hing_tokenizer, en_max_len, device)\n# print(translated_text)\n\nwith open('translated.txt', 'w', encoding='utf-8') as file:\n    for translate in translated:\n        file.write(translate + '\\n')","metadata":{"execution":{"iopub.status.busy":"2024-05-08T15:12:39.710846Z","iopub.execute_input":"2024-05-08T15:12:39.711634Z","iopub.status.idle":"2024-05-08T15:12:39.718549Z","shell.execute_reply.started":"2024-05-08T15:12:39.711602Z","shell.execute_reply":"2024-05-08T15:12:39.717497Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}