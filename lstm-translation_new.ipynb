{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8018291,"sourceType":"datasetVersion","datasetId":4724085},{"sourceId":8349977,"sourceType":"datasetVersion","datasetId":4960879},{"sourceId":8352930,"sourceType":"datasetVersion","datasetId":4962930}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# English to Hinglish Generation\n\nHere we are trying to generate Hinglish sentence by English sentence ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# dfd = pd.read_csv('/kaggle/input/hinglish-dataset/dev.txt', names=['en', 'hing'], usecols=['en', 'hing'], sep='\\t')\n# print(dfd.shape)\n# dfd = dfd.sample(frac=1, random_state=42)\n# dfd = dfd.reset_index(drop=True)\n# dfd.head()\n\n\ndf = pd.read_csv('/kaggle/input/enhingdataset/train.txt', names=['en', 'hing'], usecols=['en', 'hing'], sep='\\t')","metadata":{"execution":{"iopub.status.busy":"2024-05-08T05:25:42.453651Z","iopub.execute_input":"2024-05-08T05:25:42.454527Z","iopub.status.idle":"2024-05-08T05:25:44.130864Z","shell.execute_reply.started":"2024-05-08T05:25:42.454490Z","shell.execute_reply":"2024-05-08T05:25:44.130096Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# df1 = pd.read_csv(\"/kaggle/input/hinglish-dataset/ManualAnalysis.csv\")\n# df1 = df1[[\"src\", \"tgt\"]]\n# df1 = df1.rename(columns = {\"src\":\"en\", \"tgt\":\"hing\"})\n# df = pd.read_csv('/kaggle/input/hinglish-dataset/train.txt', names=['en', 'hing'], usecols=['en', 'hing'], sep='\\t')\n# df = df.sample(frac=1, random_state=42)\n# df = df.reset_index(drop=True)\n# df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-08T05:27:39.103546Z","iopub.execute_input":"2024-05-08T05:27:39.103897Z","iopub.status.idle":"2024-05-08T05:27:39.108374Z","shell.execute_reply.started":"2024-05-08T05:27:39.103867Z","shell.execute_reply":"2024-05-08T05:27:39.107430Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-05-08T05:27:39.933022Z","iopub.execute_input":"2024-05-08T05:27:39.933340Z","iopub.status.idle":"2024-05-08T05:27:39.954615Z","shell.execute_reply.started":"2024-05-08T05:27:39.933316Z","shell.execute_reply":"2024-05-08T05:27:39.953691Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                      en  \\\n0                             Hindi Milaap From Hyderbad   \n1                             Pension Fund Managers PFMs   \n2          A new roll of blotting paper has been ordered   \n3              Accelerated Irrigation Benefits Programme   \n4                           So they go deep inside mines   \n...                                                  ...   \n248325                    Color packages by their status   \n248326                  Disable screensaver when playing   \n248327  Default list of columns visible in the list view   \n248328                        K3b Video DVD Restrictions   \n248329                     Semi urban Areas Rs 10 00 000   \n\n                                                     hing  \n0                              Hindi Milaap From Hyderbad  \n1                                       Pension Fund PFMs  \n2        blotting paper के new roll का आदेश दिया गया है ।  \n3                    त्वरित Irrigation Benefits Programme  \n4                   इस लिए वह भूमि के अन्दर गहरे mines है  \n...                                                   ...  \n248325               packages उनकी स्थिती के अनुसार रंगें  \n248326                         screensaver निष्क्रिय करें  \n248327  list दृश्य में दृष्टिगोचर columns की Default list  \n248328                         K3b Video DVD Restrictions  \n248329                        Semi क्षेत्र में Rs 1000000  \n\n[248330 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en</th>\n      <th>hing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hindi Milaap From Hyderbad</td>\n      <td>Hindi Milaap From Hyderbad</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Pension Fund Managers PFMs</td>\n      <td>Pension Fund PFMs</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A new roll of blotting paper has been ordered</td>\n      <td>blotting paper के new roll का आदेश दिया गया है ।</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Accelerated Irrigation Benefits Programme</td>\n      <td>त्वरित Irrigation Benefits Programme</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>So they go deep inside mines</td>\n      <td>इस लिए वह भूमि के अन्दर गहरे mines है</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>248325</th>\n      <td>Color packages by their status</td>\n      <td>packages उनकी स्थिती के अनुसार रंगें</td>\n    </tr>\n    <tr>\n      <th>248326</th>\n      <td>Disable screensaver when playing</td>\n      <td>screensaver निष्क्रिय करें</td>\n    </tr>\n    <tr>\n      <th>248327</th>\n      <td>Default list of columns visible in the list view</td>\n      <td>list दृश्य में दृष्टिगोचर columns की Default list</td>\n    </tr>\n    <tr>\n      <th>248328</th>\n      <td>K3b Video DVD Restrictions</td>\n      <td>K3b Video DVD Restrictions</td>\n    </tr>\n    <tr>\n      <th>248329</th>\n      <td>Semi urban Areas Rs 10 00 000</td>\n      <td>Semi क्षेत्र में Rs 1000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>248330 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# import re\n# from unicodedata import normalize\n\n# def clean_text(text):\n#     text = text.lower()\n#     text = normalize('NFD', text)\n#     cleaned_text = ''\n#     for char in text:\n#         if char.isalpha() or char == ' ':\n#             cleaned_text += char\n#     return cleaned_text\n\n# df['en'] = df['en'].apply(lambda row: clean_text(row))\n# df['hing'] = df['hing'].apply(lambda row: clean_text(row))\n# df.head()\n\nimport numpy as np\nimport re\nfrom unicodedata import normalize\n\n\ndef clean_text(text, language='en'):\n    if isinstance(text, float) and np.isnan(text):  # Check if text is NaN\n        return ''  # Return empty string for NaN values\n    text = normalize('NFD', text)\n    if language == 'en':\n        text = re.sub('[^A-Za-z .\\']+', '', text)\n    elif language == 'hing': \n        text = re.sub('[^\\u0900-\\u097F A-Za-z .\\']+', '', text)\n    return text\n\ndef clean_and_prepare_text(text, language='hing'):\n    text = '[start] ' + clean_text(text, language=language) + ' [end]'\n    return text\n\n# Apply it to your dataframe like this:\n\n\ndf['en'] = df['en'].apply(lambda row: clean_text(row, language='en'))\ndf['hing'] = df['hing'].apply(lambda row: clean_and_prepare_text(row, language='hing'))\ndf\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-08T05:27:43.168112Z","iopub.execute_input":"2024-05-08T05:27:43.168457Z","iopub.status.idle":"2024-05-08T05:27:45.257432Z","shell.execute_reply.started":"2024-05-08T05:27:43.168431Z","shell.execute_reply":"2024-05-08T05:27:45.256549Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                      en  \\\n0                             Hindi Milaap From Hyderbad   \n1                             Pension Fund Managers PFMs   \n2          A new roll of blotting paper has been ordered   \n3              Accelerated Irrigation Benefits Programme   \n4                           So they go deep inside mines   \n...                                                  ...   \n248325                    Color packages by their status   \n248326                  Disable screensaver when playing   \n248327  Default list of columns visible in the list view   \n248328                         Kb Video DVD Restrictions   \n248329                            Semi urban Areas Rs      \n\n                                                     hing  \n0                [start] Hindi Milaap From Hyderbad [end]  \n1                         [start] Pension Fund PFMs [end]  \n2       [start] blotting paper के new roll का आदेश दिय...  \n3       [start] त्वरित Irrigation Benefits Programme [...  \n4       [start] इस लिए वह भूमि के अन्दर गहरे mines है ...  \n...                                                   ...  \n248325  [start] packages उनकी स्थिती के अनुसार रंगें [...  \n248326           [start] screensaver निष्क्रिय करें [end]  \n248327  [start] list दृश्य में दृष्टिगोचर columns की D...  \n248328            [start] Kb Video DVD Restrictions [end]  \n248329                 [start] Semi क्षेत्र में Rs  [end]  \n\n[248330 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en</th>\n      <th>hing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hindi Milaap From Hyderbad</td>\n      <td>[start] Hindi Milaap From Hyderbad [end]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Pension Fund Managers PFMs</td>\n      <td>[start] Pension Fund PFMs [end]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A new roll of blotting paper has been ordered</td>\n      <td>[start] blotting paper के new roll का आदेश दिय...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Accelerated Irrigation Benefits Programme</td>\n      <td>[start] त्वरित Irrigation Benefits Programme [...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>So they go deep inside mines</td>\n      <td>[start] इस लिए वह भूमि के अन्दर गहरे mines है ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>248325</th>\n      <td>Color packages by their status</td>\n      <td>[start] packages उनकी स्थिती के अनुसार रंगें [...</td>\n    </tr>\n    <tr>\n      <th>248326</th>\n      <td>Disable screensaver when playing</td>\n      <td>[start] screensaver निष्क्रिय करें [end]</td>\n    </tr>\n    <tr>\n      <th>248327</th>\n      <td>Default list of columns visible in the list view</td>\n      <td>[start] list दृश्य में दृष्टिगोचर columns की D...</td>\n    </tr>\n    <tr>\n      <th>248328</th>\n      <td>Kb Video DVD Restrictions</td>\n      <td>[start] Kb Video DVD Restrictions [end]</td>\n    </tr>\n    <tr>\n      <th>248329</th>\n      <td>Semi urban Areas Rs</td>\n      <td>[start] Semi क्षेत्र में Rs  [end]</td>\n    </tr>\n  </tbody>\n</table>\n<p>248330 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"en = df['en']\nhing = df['hing']\n\nen_max_len = max(len(line.split()) for line in en)\nhing_max_len = max(len(line.split()) for line in hing)\n\nprint(f'Max phrase length (English): {en_max_len}')\nprint(f'Max phrase length (Hinglish): {hing_max_len}')\n\nsequence_len = max(en_max_len,hing_max_len)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-08T05:27:46.513292Z","iopub.execute_input":"2024-05-08T05:27:46.513651Z","iopub.status.idle":"2024-05-08T05:27:46.951094Z","shell.execute_reply.started":"2024-05-08T05:27:46.513623Z","shell.execute_reply":"2024-05-08T05:27:46.950195Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Max phrase length (English): 10\nMax phrase length (Hinglish): 114\n","output_type":"stream"}]},{"cell_type":"code","source":"from collections import defaultdict\nimport torch\nclass Tokenizer:\n    def __init__(self):\n        self.word_index = {}\n        self.index_word = {}\n    \n    def fit_on_texts(self, texts):\n        word_freq = defaultdict(int)\n        for text in texts:\n            for word in text.split():\n                word_freq[word] += 1\n        self.word_index = {word: i+1 for i, (word, freq) in enumerate(sorted(word_freq.items(), key=lambda x: x[1], reverse=True))}\n        self.index_word = {i: word for word, i in self.word_index.items()}\n\n    def texts_to_sequences(self, texts):\n        sequences = []\n        for text in texts:\n            seq = [self.word_index.get(word, 0) for word in text.split()]\n            sequences.append(seq)\n        return sequences\n    \n    def sequences_to_texts(self, sequences):\n        texts = []\n        for sequence in sequences:\n            words = [self.index_word.get(idx, \"<unk>\") for idx in sequence if idx > 0]  # Skip padding\n            text = \" \".join(words)\n            texts.append(text)\n        return texts\n\ndef pad_sequences(sequences, maxlen, padding='post'):\n    max_seq_len = max(len(seq) for seq in sequences)\n    padded_seqs = torch.zeros((len(sequences), maxlen), dtype=torch.long)\n    for i, seq in enumerate(sequences):\n        if padding == 'post':\n            padded_seqs[i, :len(seq)] = torch.tensor(seq[:maxlen], dtype=torch.long)\n        else:  \n            padded_seqs[i, -len(seq):] = torch.tensor(seq[-maxlen:], dtype=torch.long)\n    return padded_seqs\n\nen_tokenizer = Tokenizer()\nen_tokenizer.fit_on_texts(en)\nen_sequences = en_tokenizer.texts_to_sequences(en)\nen_x = pad_sequences(en_sequences, maxlen=en_max_len, padding='post')\n\nhing_tokenizer = Tokenizer()\nhing_tokenizer.fit_on_texts(hing)\nhing_sequences = hing_tokenizer.texts_to_sequences(hing)\nhing_y = pad_sequences(hing_sequences, maxlen=hing_max_len, padding='post')","metadata":{"execution":{"iopub.status.busy":"2024-05-08T05:27:50.242882Z","iopub.execute_input":"2024-05-08T05:27:50.243739Z","iopub.status.idle":"2024-05-08T05:28:05.405617Z","shell.execute_reply.started":"2024-05-08T05:27:50.243706Z","shell.execute_reply":"2024-05-08T05:28:05.404800Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"en_vocab_size = len(en_tokenizer.word_index) + 1\nhing_vocab_size = len(hing_tokenizer.word_index) + 1\n\nprint(f'Vocabulary size (English): {en_vocab_size}')\nprint(f'Vocabulary size (Hinglish): {hing_vocab_size}')","metadata":{"execution":{"iopub.status.busy":"2024-05-08T05:28:05.407076Z","iopub.execute_input":"2024-05-08T05:28:05.407455Z","iopub.status.idle":"2024-05-08T05:28:05.412889Z","shell.execute_reply.started":"2024-05-08T05:28:05.407431Z","shell.execute_reply":"2024-05-08T05:28:05.412025Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Vocabulary size (English): 81406\nVocabulary size (Hinglish): 114113\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Train a model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, en_vocab_size, hing_vocab_size, hidden_size):\n        super(Seq2Seq, self).__init__()\n        self.embedding = nn.Embedding(en_vocab_size, 300)\n        self.encoder = nn.LSTM(300, hidden_size)\n        self.decoder = nn.LSTM(hidden_size, hidden_size)\n        self.linear = nn.Linear(hidden_size, hing_vocab_size)\n        self.dropout = nn.Dropout(0.4)\n\n    def forward(self, x):\n        embedded = self.embedding(x)\n        encoded, (hidden, cell) = self.encoder(embedded)\n        decoded = self.dropout(encoded)\n        decoded, _ = self.decoder(decoded, (hidden, cell))\n        output = self.linear(decoded)\n        return output\n\ntorch.manual_seed(42)\nnp.random.seed(42)\n\nhidden_size = 256\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = Seq2Seq(en_vocab_size, hing_vocab_size, hidden_size).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters())\n\nen_x = torch.tensor(en_x, dtype=torch.long).to(device)\nhing_y = torch.tensor(hing_y, dtype=torch.long).to(device)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-08T05:43:48.093108Z","iopub.execute_input":"2024-05-08T05:43:48.094105Z","iopub.status.idle":"2024-05-08T05:43:51.375783Z","shell.execute_reply.started":"2024-05-08T05:43:48.094068Z","shell.execute_reply":"2024-05-08T05:43:51.374818Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/4092959309.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  en_x = torch.tensor(en_x, dtype=torch.long).to(device)\n/tmp/ipykernel_34/4092959309.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  hing_y = torch.tensor(hing_y, dtype=torch.long).to(device)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the model\nnum_epochs = 20\nbatch_size = 16\nvalidation_split = 0.2\n\naccumulation_steps = 4\ntrain_losses = []\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    optimizer.zero_grad()  \n    for i in range(0, len(en_x), batch_size):\n        inputs = en_x[i:i+batch_size]\n        labels = hing_y[i:i+batch_size]\n\n        outputs = model(inputs)\n        outputs = outputs.permute(1, 0, 2)  \n        outputs = outputs.reshape(-1, hing_vocab_size)  \n\n        labels = labels.permute(1, 0)  \n        flat_labels = labels.reshape(-1)\n\n        if outputs.size(0) > flat_labels.size(0):\n            outputs = outputs[:flat_labels.size(0), :]\n        elif outputs.size(0) < flat_labels.size(0):\n            flat_labels = flat_labels[:outputs.size(0)]\n\n        loss = criterion(outputs, flat_labels)\n        (loss / accumulation_steps).backward()  \n        running_loss += loss.item()\n\n        if (i // batch_size + 1) % accumulation_steps == 0:\n            optimizer.step()\n            optimizer.zero_grad()\n\n    running_loss /= (len(en_x) / batch_size)\n    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss:.4f}')\n    train_losses.append(running_loss)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T22:00:22.754859Z","iopub.execute_input":"2024-05-07T22:00:22.755505Z","iopub.status.idle":"2024-05-07T22:00:30.354775Z","shell.execute_reply.started":"2024-05-07T22:00:22.755476Z","shell.execute_reply":"2024-05-07T22:00:30.353329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:12:52.725496Z","iopub.status.idle":"2024-05-07T21:12:52.725949Z","shell.execute_reply.started":"2024-05-07T21:12:52.725702Z","shell.execute_reply":"2024-05-07T21:12:52.725720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot the per-epoch training and validation accuracy:","metadata":{}},{"cell_type":"code","source":"# # Train the model\n# # num_epochs = 20\n# # batch_size = 16\n# # validation_split = 0.2\n\n# # accumulation_steps = 4\n# # train_losses = []\n\n# model.eval() \n# for i in range(0, len(en_x)):\n#     inputs = en_x[i:i+batch_size]\n#     labels = hing_y[i:i+batch_size]\n\n#     outputs = model(inputs)\n#     outputs = outputs.permute(1, 0, 2)  \n#     outputs = outputs.reshape(-1, hing_vocab_size)  \n\n#     labels = labels.permute(1, 0)  \n#     flat_labels = labels.reshape(-1)\n\n#     if outputs.size(0) > flat_labels.size(0):\n#         outputs = outputs[:flat_labels.size(0), :]\n#     elif outputs.size(0) < flat_labels.size(0):\n#         flat_labels = flat_labels[:outputs.size(0)]\n\n#     loss = criterion(outputs, flat_labels)\n#     (loss / accumulation_steps).backward()  \n#     running_loss += loss.item()\n\n#     if (i // batch_size + 1) % accumulation_steps == 0:\n#         optimizer.step()\n#         optimizer.zero_grad()\n\n# running_loss /= (len(en_x) / batch_size)\n# print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss:.4f}')\n# train_losses.append(running_loss)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:12:52.727192Z","iopub.status.idle":"2024-05-07T21:12:52.727691Z","shell.execute_reply.started":"2024-05-07T21:12:52.727426Z","shell.execute_reply":"2024-05-07T21:12:52.727446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using model to translate text","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = Seq2Seq(en_vocab_size, hing_vocab_size, hidden_size = 256).to(device)\nmodel.load_state_dict(torch.load('/kaggle/input/lstmmodel/model.pth'))\n# torch.load('/kaggle/input/lstmmodel/model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-05-08T05:28:52.483829Z","iopub.execute_input":"2024-05-08T05:28:52.484674Z","iopub.status.idle":"2024-05-08T05:28:55.239060Z","shell.execute_reply.started":"2024-05-08T05:28:52.484641Z","shell.execute_reply":"2024-05-08T05:28:55.238172Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"def translate_text_pytorch(text, model, en_tokenizer, hing_tokenizer, en_max_len, device):\n    # Tokenizing the input text\n    sequence = en_tokenizer.texts_to_sequences([text])\n    padded_sequence = torch.tensor(sequence, dtype=torch.long, device=device)  # Directly create tensor on device\n    \n    padded_sequence = padded_sequence.to(device).long()\n    \n    if len(padded_sequence.shape) == 1:\n        padded_sequence = padded_sequence.unsqueeze(0)\n    \n    model.eval()\n    with torch.no_grad():\n        prediction = model(padded_sequence).squeeze(0)\n    \n    prediction = prediction.cpu().numpy()  # Move prediction to CPU for NumPy operations\n    indexes = [np.argmax(idx) for idx in prediction]\n    translated_text = hing_tokenizer.sequences_to_texts([indexes])[0]\n    \n    return translated_text\n\n\ndf_test = pd.read_csv('/kaggle/input/enhingdataset/test.txt', names=['en', 'hing'], usecols=['en', 'hing'], sep='\\t')\ndf_test['en'] = df_test['en'].apply(lambda row: clean_text(row, language='en'))\ndf_test['hing'] = df_test['hing'].apply(lambda row: clean_and_prepare_text(row, language='hing'))\nen_test = df_test['en']\nhing_test = df_test['hing']\n\n\ntexts = list(en_test)\ntranslated = []\nfor text in texts:\n    translated.append(translate_text_pytorch(text, model, en_tokenizer, hing_tokenizer, en_max_len, device))\n#     print(f'{text} => {translated}')","metadata":{"execution":{"iopub.status.busy":"2024-05-08T05:28:57.773110Z","iopub.execute_input":"2024-05-08T05:28:57.773464Z","iopub.status.idle":"2024-05-08T05:29:02.070550Z","shell.execute_reply.started":"2024-05-08T05:28:57.773436Z","shell.execute_reply":"2024-05-08T05:29:02.069687Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# for i in range(20) :\n#     print(f'{translated[i]}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-07T22:02:33.812968Z","iopub.execute_input":"2024-05-07T22:02:33.813327Z","iopub.status.idle":"2024-05-07T22:02:33.817648Z","shell.execute_reply.started":"2024-05-07T22:02:33.813299Z","shell.execute_reply":"2024-05-07T22:02:33.816670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Translating \"you are good\"\n# translated_text = translate_text_pytorch('you are good', model, en_tokenizer, hing_tokenizer, en_max_len, device)\n# print(translated_text)\n\nwith open('translated.txt', 'w', encoding='utf-8') as file:\n    for translate in translated:\n        file.write(translate + '\\n')","metadata":{"execution":{"iopub.status.busy":"2024-05-08T05:32:35.827945Z","iopub.execute_input":"2024-05-08T05:32:35.828844Z","iopub.status.idle":"2024-05-08T05:32:35.836003Z","shell.execute_reply.started":"2024-05-08T05:32:35.828810Z","shell.execute_reply":"2024-05-08T05:32:35.834884Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"The model isn't that good, as the bleu score for this is around 0.0193 only","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}